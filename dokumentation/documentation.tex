\documentclass[a4paper, 12pt]{scrreprt}

\pagenumbering{roman}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{2} 

\usepackage[german]{babel}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
%\usepackage{fancyhdr}
\usepackage{geometry}
\usepackage{lmodern}
\usepackage{verbatim}
\usepackage{graphicx}
\usepackage[hyphens]{url}
\usepackage[pdfborder={0 0 0}]{hyperref}
\usepackage{listings}
\renewcommand\_{\textunderscore\allowbreak}
\usepackage{float}

\usepackage{caption}

\usepackage{amsmath}
\usepackage{blindtext}


\usepackage{fancybox}
\usepackage{makeidx}% \makeindex
\usepackage{lastpage}
\usepackage{natbib}

%\linespread{1.5}
%\geometry{footskip=40pt}
\setcounter{page}{2}
\linespread{1.25}


\begin{document}

\begin{titlepage}
%\includegraphics[scale=0.3]{Z1.png} \hfill
%\includegraphics[scale=0.1]{2.png}\\[1.8cm]
    \begin{center}
    \LARGE \textbf{VirtualDesktop} \\
    \vspace{2.5cm}
    \large\textbf{Projekt}\\
    \vspace{2.5cm}
    \normalsize
    Hochschule RheinMain Wiesbaden \\
    \vspace{2cm}
    \large \textbf{Fortgeschrittene Themengebiete der Informatik\\ Cloud Computing\\}
    \vspace{1cm}
    \normalsize
    Abgabedatum: 30. Januar 2019\\
    \vspace{2.7cm}
    \end{center}
 \normalsize{
    \begin{tabular}{ll}
    	Gruppe: & \\
    	Robin Bergfeld & \\
    	Abiram Pakeerathan & \\
    	Simon Rininsland & \\[0.5cm]
    	Dozent: &\\
        Prof. Dr. Philipp Schaible & \\
    \end{tabular}
    }
\end{titlepage}



\clearpage
\tableofcontents
\clearpage

\pagenumbering{arabic}

%zitieren:
% \cite{Joa10:1}

\chapter{Einführung}
%Mit was, wer wo...
Im Rahmen des Moduls Cloud Computing an der Hochschule RheinMain im Wintersemester 2018 / 2019 bei Prof. Dr. Schaible ist eine Web-Anwendung unter Verwendung von Amazon Web-Services (AWS) entwickelt worden. Zunächst werden in diesem Kapitel die vorgegebenen sowie selbst hinzugefügten Anforderungen beschrieben. Anschließend wird die entwickelte Webanwendung \textit{VirtualDesktop} vorgestellt.\\ 
In nachfolgenden Kapiteln werden Architektur, verschiedene Besonderheiten sowie die Kosten für diese Anwendung thematisiert.

\section{Projektanforderungen}
%- Welche Anforderungen vom Modul\\
%- Fokus des Projekts
Es ist eine Web-Anwendung unter Verwendung von Amazon Web-Services (AWS) zu
entwickeln, die mindestens folgende Funktionalitäten beinhalten soll.
\begin{enumerate}
\item Eine statische Web-Seite als Startpunkt der Anwendung.
\item Ausgelagerte REST APIs für dynamisches Verhalten der Anwendung.
\item Benutzerverwaltung mit expliziten Authentifizierungs- und Autorisierungsverwaltung.
\item Die Daten der Anwendung sollen in einer Datenbank verwaltet werden. Die SQL und NoSQL Datenbanken sollen dabei passend eingesetzt werden.
\item Die Anwendung soll mit heterogenen Daten umgehen können. Zusätzlich zu den
organisatorischen Daten (Nutzerverwaltung, Anwendungslogik, etc.) müssen
Multimedia-Daten (Bilder, Audio, Video) integriert werden. Es muss dabei möglich
sein, die Multimedia-Daten entweder herunterzuladen oder zu streamen.
\item Die Anwendung muss horizontal skalierbar sein. (Begründung!)
\end{enumerate}
\bigskip\bigskip
Zusätzlich haben wir folgende eigene Projektanforderungen hinzugefügt:
\begin{enumerate}
\item Die Anwendung soll auf spätere Socketnutzung ausgelegt sein.
\item Der Code soll in einen öffentlichen Repository liegen.
\item Der Stack ist von jedem Deploybar. Das Template des Stacks soll also nur mit variablen Namen arbeiten und der Stack soll mit einen Befehl aufgebaut werden.
\item Der Code der Anwendung soll sauber in Model, View und Controller getrennt sein. 
\item Die NodeJS Funktionen sollen möglichst parallel arbeiten.
\item Der Up- und Download soll über Streams geschehen, um auf der Laufzeitumgebung keine Daten speichern zu müssen.
\end{enumerate}

\newpage
\section{VirtualDesktop}
%- Was mit Bildern (kurz, vielleicht nur ein Bild)\\
%- Funktionen erläutern (MultiWindow, Benutzerverwaltung inkl Rechteverwaltung, Stream, Up-Download, Show)\\
%- Ziel des Produkts (müssen sich mit Anforderungen des Moduls decken)\\

Die Web-Anwendung \textit{VirtualDesktop} soll registrierten Benutzern virtuelle Desktops zur Verfügung stellen, die auf jedem Gerät aufrufbar sind und mit anderen Benutzern geteilt werden können. Die erstellten Desktops sollen zur Multimediaablage genutzt werden. Der Up- und Download ist mit beliebigen Dateitypen möglich. Zusätzlich können Bilder angezeigt sowie Audio- und Video-Daten gestreamt werden.\\[0.25cm]
Alle Benutzer müssen sich anmelden um die Anwendung nutzen zu können. Ein Benutzer kann mehrere Desktops anlegen und diese verwalten. Das Anlegen von mehreren Desktops ist zum Beispiel dann sinnvoll, wenn die Desktops mit unterschiedlichen Personengruppen geteilt werden sollen.
Für jeden angelegten Desktop, kann der Ersteller andere Nutzer hinzufügen und ihnen verschiedene Rechte an seinem Desktop zuweisen.\\
Mit zugewiesenen Leserechten kann der Nutzer Dateien betrachten und herunterladen, mit Schreibrechten darf der Nutzer auch eigene Dateien auf diesem Desktop ablegen. Dem Nutzer müssen explizit Löschrechte zugewiesen werden, um Dateien von fremden Desktops entfernen zu können.\\
Nutzer können auch Admin-Rechte erhalten, sodass diese für den Desktop Nutzerrechte bearbeiten und neue Nutzer hinzufügen dürfen. Ein angelegter Desktop kann aber nur vom Ersteller selbst entfernt werden.\\ 
Es gibt also
\begin{itemize} 
\item[] \textbf{Owner}, die einen oder mehrere Desktops angelegt haben, zwischen diesen wechseln können und andere Nutzer durch Zuweisung von Lese- , Schreib- und Löschrechten zu ihren Desktops hinzufügen können. Sie besitzen für ihre eigenen Desktops alle Rechte. Sie können auch Admin-Rechte, für die Bearbeitung von Nutzerrechten, vergeben.
\item[] \textbf{User}, die Rechte für einen oder mehrere Desktops zugewiesen bekommen haben und zwischen diesen wechseln können und diesen Rechten entsprechend Aktionen ausführen dürfen.
\end{itemize} 

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{VD_konzept.pdf}
\caption{Username1 ist Owner und besitzt drei Desktops. DESKTOP1 teilt Username1 mit Username4 und Username7. Der DESKTOP2 wird nur mit Username7 geteilt. Den Usern wurden individuell für diese Desktops Rechte zugeteilt. Den DESKTOP3 kann nur der Owner selbst betrachten.}
\end{figure}

\noindent Ein Anwender, der nicht explizit jedem mit dem er seinen Desktop zu teilen vermag, Rechte zuweisen möchte, weil es sich z.B. um eine sehr große Anzahl von Personen handelt, kann als \textit{Owner} seinen Desktop auf public setzen.
Da Desktopnamen in \textit{VirtualDesktop} global eindeutig sind, kann dieser Desktop dann über den Desktopnamen geteilt und gefunden werden.
\textit{User} haben auf einem, auf public gesetzten, Desktop nur Leserechte, außer ihnen wurden explizit weitere Rechte zugewiesen. 
Nur dem \textit{Owner} ist es erlaubt den Desktop wieder auf privat zu setzen, auch \textit{Usern} mit Admin-Rechten für diesen Desktop ist dies nicht gestattet.

\chapter{Der Weg in die Cloud}
Unsere Projektanforderungen an die Architektur umfasst einen klassischen Aufbau eines Web Projektes mit folgenden Anforderungen. \\

\begin{itemize}
\item Eine Anwendungsumgebung, die die Geschäftslogik abbildet.
\item Eine Datenbank, die auch mit vielen Zugriffen schnell bleibt.
\item Einen Speicher, der die Daten von den Nutzern speichert.
\item Alle Zugriffe müssen authentifiziert werden.
\item Es sollen immer aktuelle Sicherheitspatches installiert sein.
\item Skalierung soll jederzeit möglich sein, um beliebig viele Nutzer bedienen zu können.
\item Die Kosten sollen möglichst gering sein.
\end{itemize}
Es wäre durchaus denkbar die ersten fünf Punkte gut auf einer lokalen Serverumgebung umzusetzen. Spätestens aber bei der beliebigen Skalierung stößt man auf Probleme. 
\\
Die auf einer klassischen Serverumgebung einfach mögliche vertikale Skalierung stößt schnell auf ihre Grenzen. Früher oder später wird vermutlich die Datenbank in jedem System der Flaschenhals werden und diese dann horizontal zu skalieren ist meist mit großen strukturellen und/oder architektonischen Änderungen verbunden. Es gibt verschiedenste Datenbanktypen, die meist genutzten sind nur schwer skalierbar. Cloudanbieter bieten Datenbanken an, die automatisch skalieren und die sich automatisch über mehrere Regionen replizieren. Alleine diese Datenbankskalierung wäre mit sehr viel händischen Aufwand und Kosten verbunden. \\ 
Anstatt sich händisch darum zu kümmern, dass sein System aktuell bleibt, kann man bei Cloudservices auf die Expertise vom Cloudanbieter zurückgreifen. Updates und Sicherheitspatches werden automatisch eingespielt. \\
Die Skalierung klassischer Webprojekte läuft so, dass die Infrastruktur für die maximale Nutzung aufgebaut wird. Das bedeutet, dass bei hoher kurzzeitiger Nutzung Ressourcen aufgebaut werden, die dann kurz danach nicht mehr benötigt werden. Ein Rückbau wird selten gemacht und Ressourcen liegen brach. Dieses überpowern der Infrastruktur birgt vermeidbare Mehrkosten. Cloudanbieter rechnen immer nur den aktuellen Verbrauch ab. Wird ein Server Nachts nicht genutzt, werden keine Kosten generiert. Alle zusätzlichen Kosten einer klassischen Infrastruktur wie Wartung, sind darin bereits inkludiert. \\
Das Problem einer klassischen Webanwendung ist der vertikale Aufbau des Server, in dem alle Services enthalten sind. Skalierung in einer beliebigen Größe ist nur möglich, wenn alle Services getrennt voneinander skalierbar sind. Cloudanbieter bieten dann an diese einzelnen Services getrennt laufen zu lassen und zu skalieren. \\
Es gibt verschiedene Cloudanbieter wie GoogleCloud von Google, Azure von Microsoft oder AWS von Amazon. Hat man sich für einen Anbieter entschieden bringt dies ein Problem mit sich den \textit{Cloud-Lock-In}. Der \textit{Cloud-Lock-In} führt dazu, dass für die Entwicklung der Anwendung Cloudanbieter eigenen Technologien verwendet werden. Diese sind jedoch nicht standardisiert und ein Umzug ist daher meist nur mit hohen Aufwand möglich. Außerdem gibt man mit dem Weg in die Cloud Kontrolle ab. Viele Parameter, werden vom Cloudanbieter gesteuert, die man nicht mehr in der Hand hat.\\
Nach einmaliger Einarbeitungsphase in die Services des Cloudanbieters kann man sich jedoch auf die Entwicklung der Kernanwendungen konzentrieren. 
Für dieses Projekt fiel die Entscheidung auf AWS von Amazon.

\chapter{Architektur}
% Clouformation ansprechen
% Hier wie deploye ich rein
Um in AWS seinen Service Stack zu persistieren haben wir \textit{Clouformation} genutzt. In \textit{Cloudformation} wird anhand einer template Datei der Stack in JSON oder YAML beschrieben. Innerhalb dieses Projektes wird YAML verwendet.\\
Wie bereits in den Anforderungen beschrieben, haben wir uns als Ziel gesetzt den gesamten Service Stack mit einen Befehl ausrollen zu können. Der Befehl mit den Parametern wird im setup Ordner ausgeführt und ist folgender:

\bigskip
\begin{lstlisting}[xleftmargin=\parindent,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
node index.js create <aws_key_id> <aws_access_key> 
<stack_name> [<domainName>]
\end{lstlisting}
\bigskip

\noindent Die Voraussetzung, um unser Stack Deployment Script ausführen zu können ist die Installation von \textit{node}, \textit{aws-cli} und ein anschließendes \textit{npm install}.
Mit der Ausführung des Scripts werden die Lambda und unsere Anwendung inklusive der benötigten Dateien in einen \textit{CodeBucket} hochgeladen, womit in \textit{Cloudformation} dann die Anwendungen aufgebaut werden.\\ Ein Abbau des Stacks ist ebenso möglich über:
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
node index.js delete <aws_key_id> <aws_access_key>
 <tmp_code_bucket_name> <stack_name>
\end{lstlisting}
\bigskip
Dieser Aufruf wird nach dem ausführen des deployment Scripts mit den bereits ausgefüllten Parametern ausgegeben.\\

\newpage
\noindent Die daraus entstehende Servicearchtitektur kann man in folgender Grafik zusammenfassen.

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{ArchiDiagram.png} 
\caption{Architekturdiagramm VirtualDesktop}
\end{figure}

\noindent Im folgenden Abschnitten werden die einzelnen Services und deren Konfiguration in \textit{Cloudformation} beschrieben. 


\section{Elastic Beanstalk Konfiguration}
Die Geschäftslogik wird in unserer EC2 Instanz abgewickelt, welcher in ein ElasticBeanstalk Stack skaliert wird. Dieser Stack sorgt dafür, dass die EC2 Instanz im Speicher, in der Rechenleistung, im Netzwerk wie auch im Arbeitsspeicher den Anforderung entsprechend skaliert. Wie man nachfolgend sehen kann, braucht eine Elastic-Beanstalk Applikation auch immer ein Elastic-Beanstalk Umgebung und ein Konfigurationstemplate. Die ElasticBeanstalk Konfiguration soll hier in Auszügen gezeigt werden.
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
ElasticBS:
        Type: AWS::ElasticBeanstalk::Application
        Properties:
            Description: ElasticBeanstalk VirtualDesktop
    ApplicationVersionElasticBS:
        Type: AWS::ElasticBeanstalk::ApplicationVersion
        Properties:
            ApplicationName:
                Ref: ElasticBS
            Description: ElasticBeanstalk VirtualDesktop
             Application Version
            SourceBundle:
                S3Bucket:
                    Ref: CodeBucket
                S3Key: ebs.zip
\end{lstlisting}
\bigskip
Interessant ist hier die ElasticBeanstalk Applikation zugrunde liegende Code, der in einen separaten CodeBucket als zip vorliegt. Von dort aus wird die Applikation in der EC2 Instanz gebaut.\\
Die ElasticBeanstalk Umgebung
 \textit{AWS::ElasticBeanstalk::Environment} beinhaltet die Konfiguration der eigentlichen Instanz.
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
    EnvironmentElasticBS:
        Type: AWS::ElasticBeanstalk::Environment
        Properties:
            ApplicationName:
                Ref: ElasticBS
            Description: AWS ElasticBeanstalk VirtualDesktop 
            Environment
            TemplateName:
                Ref: ConfigurationElasticBS
            VersionLabel:
                Ref: ApplicationVersionElasticBS
            OptionSettings:
            -
                Namespace: aws:autoscaling:launchconfiguration 
                OptionName: IamInstanceProfile
                Value: aws-elasticbeanstalk-ec2-role
            -
                Namespace: aws:elasticbeanstalk:container:nodejs
                OptionName: NodeCommand
                Value: "npm start"
\end{lstlisting}
\bigskip
\noindent Dort werden zum Beispiel die Laufzeit und die Umgebungsvariablen über die ElasticBeanstalk Konfiguration festgelegt. Auch den Start Befehl beim hochfahren der Instanz kann man dort festlegen.\\
ElasticBeanstalk legt neben den hier beschriebenen Services auch Services an, die nicht explizit konfiguriert werden, wie einen \textit{LoadBalancer}, \textit{CloudWatch} und verschiedenste Berechtigungen. Dies benötigt ElasticBeanstalk, um die automatische Skalierung überhaupt möglich zu machen.\\[0.5cm]
Die EC2 Instanz beinhaltet unsere NodeJS Applikation und stellt sowohl das Front- wie Backend. Mit einer API werden dort die Operationen auf den AWS-Services koordiniert und gesteuert. 
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
ConfigurationElasticBS:
        Type: AWS::ElasticBeanstalk::ConfigurationTemplate
        Properties:
            ApplicationName:
                Ref: ElasticBS
            Description: AWS ElasticBeanstalk VirtualDesktop 
            Configuration
            OptionSettings:
            -
                Namespace: aws:autoscaling:asg
                OptionName: MinSize
                Value: '1'
\end{lstlisting}

\section{Authentifizierungsservice Cognito}
%Inhaltlich gut
Zur Authentifizierung von Nutzern wird Amazon Cognito verwendet. Der Nutzerpool \textit{Cognitopool} vom Typ \textit{AWS::Cognito::UserPool} ist so konfiguriert, dass bei der Registrierung eines neuen Nutzers ein Passwort angegeben werden muss, welches die Minimalvorrausetzung eines AWS-Cognito-Passworts erfüllt (Zeichenlänge von Sechs \cite{AWSD}). Für die Registriereung muss der Nutzer sich verifizieren. Dies geschieht hier über Email, in der der Nutzer seinen Bestätigungscode erhält. Die Formatierung dieser Email wird in \textit{EmailVerificationMessage} und \textit{EmailVerificationSubject} angegeben.  
%COGNITO MINLÄNGE
%https://docs.aws.amazon.com/de_de/AWSCloudFormation/latest/UserGuide/aws-properties-cognito-userpool-passwordpolicy.html
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
CognitoPool:
        Type: AWS::Cognito::UserPool
        Properties:
            AutoVerifiedAttributes:
                -
                    "email"
            EmailVerificationMessage: "Here is your code: {####}"
            EmailVerificationSubject: "Verify your E-Mail for VD"
            Policies:
                PasswordPolicy:
                    MinimumLength: "6"
                    RequireLowercase: false
                    RequireNumbers: false
                    RequireSymbols: false
                    RequireUppercase: false

\end{lstlisting}
\bigskip
\noindent Um den \textit{UserPool} verwenden zu können, benötigt dieser einen Benutzer, den \textit{AWS::Cognito::UserPoolClient}. Dieser wird über die Property \textit{UserPoolId} an den angegeben \textit{UserPool} gebunden, in diesem Fall wird eine Referenz auf den zuvor angelegten UserPool mit dem Namen \textit{CognitoPool} angegeben. Die Property \textit{GenerateSecret} wird hier auf \textit{false} gesetzt, da die clientseitig verwendete Amazon Cognito Identity-SDK für JavaScript keine client secrets unterstützt \cite{AWSAmplify}.
%generateSec QUelle
%https://github.com/aws-amplify/amplify-js/tree/master/packages/amazon-cognito-identity-js
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
    CognitoClient:
        Type: AWS::Cognito::UserPoolClient
        Properties:
            GenerateSecret: false
            UserPoolId: '{"Ref" : "CognitoPool"}'
\end{lstlisting} 

\section{Cloud-Speicher S3}
Unsere Applikation benötigt insgesamt drei \textit{S3-Buckets.} Der erste Bucket, auch später \textit{Code Bucket} genannt, wird nur temporär während des Aufbaus des Stacks benötigt. Cloudformation setzt die gezippte Anwendung inklusive Template Definition beim Aufbau voraus. Dieser Bucket wird beim entfernen des Stacks mit dem Deployment Script wieder gelöscht. \\
Ein weiterer Bucket wird benötigt, um die Multimediadaten der Nutzer zu speichern. Dieser Bucket wird im folgenden \textit{User Bucket} genannt. \\
Zuletzt wird ein weiterer Bucket genutzt, um die Thumbnails der Bilder, die durch den verwendeten LambdaService generiert werden, zu speichern. Der \textit{Thumbnail Bucket}, hat ein Präfix \textit{thumbs} und sonst denselben generischen Namen wie der \textit{User Bucket}. \\
Durch folgende Beschreibung in der Konfiguration wird der \textit{Thumbnail Bucket} erstellt.
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
ThumbBucket:
    Type: AWS::S3::Bucket
    Properties:
        BucketName: !Sub
            - thumbs{ResBucket}
            - ResBucket: !Ref Bucket
\end{lstlisting}     
\bigskip     
Auch die S3-Buckets haben in AWS eine automatische Skalierung inne. Sowohl in der Größe, wie auch in der genutzten Bandbreite ist der Speicher variabel und passt sich den Umständen an.
%das hier umformulieren? beliebig skalierbare Datenspeicher, Bandbreite? Umstände?

\section{Datenbank DynamoDB}
\label{db}
%etwas genauer sagen wieso dynamodb statt sql für daten
Aufgrund der Architektur der Applikation und der Festlegung die Infrastruktur in der Cloud laufen zu lassen, kam für uns nur eine NoSQL- Datenbank wie DynamoDB in Frage. Da den Anforderungen nach von großen Nutzerzahlen ausgegangen wird, ist es sinnvoll eine NoSQL für die Anwendungsdaten zu verwenden. Für die Berechtigungsdaten könnte in der Regel eine SQL-Datenbank in betracht gezogen werden, jedoch ist der Durchsatz für die Berechtigungstabelle höher einzuschätzen, da diese für jeden Ressourcenaufruf mit Ausnahme von \textit{createWindow} abgefragt werden muss. Daher ist die Verwendung einer NoSQL-Datenbank auch für die Berechtigungsdaten notwendig.\\
Das Erstellung einer Datenbanktabelle in der DynamoDB wird hier exemplarisch an der \textit{Permissions}-Tabelle vom Typ \textit{AWS::DynamoDB::Table} gezeigt. Anders als bei klassischen SQL-Datenbanken kann ein Eintrag in einer DynamoDB-Tabelle beliebige Felder beinhalten. Diese werden lediglich über den Schlüssel abgefragt. Um den Schlüssel einer Tabelle zu definieren muss der \textit{AttributeType}, der \textit{AttributeName} und der \textit{KeyType} innerhalb der \textit{AttributeDefinitions} und \textit{KeySchema} angegeben werden. Diese beiden Felder sind erforderlich, müssen also angegeben werden. Das selbe gilt für \textit{ProvisionedThroughput} \cite{AWSDa}.
Dies bedeutet, dass die Skalierung nicht bei der Erstellung durch CloudFormation oder EBS eingestellt werden werden. Um die DynamoDB zu skalieren muss \textit{AWSServiceRoleForApplicationAutoScaling\_DynamoDBTable} im AWS-Account aktiv sein. Falls \textit{AWSServiceRoleForApplicationAutoScaling\_DynamoDBTable} bereits bei der Erstellung durch EB-Deploy aktiviert war skalieren die Tabellen,  ansonsten nicht. Das Autoscaling für die Tabellen kann dann jedoch nachträglich über die Management-Console eingestellt werden. Nähere Informationen hierzu sind in \cite{AWSDb} zu finden.
\\[0.5cm]
%- Was ist das Problem. Nicht mehrere Sachen löschen nicht möglich.
Da die DynamoDB nicht über die Möglichkeit verfügt, mehrere Einträge über einen Key zu entfernen, muss für die \textit{deleteWindow}-Funktion die gesamte \textit{File}-Liste und \textit{Permission}-Liste für den gegebenen Key eingelesen und jeder Eintrag einzeln in der DynamoDB entfernt werden.
Um nicht jeden Listeneintrag einzeln zu entfernen kann zwar \textit{batchWriteItem} verwendet werden, dieses ist jedoch max. auf 25 DeleteItem-Operationen limitiert und es können keine \textit{conditions} angegeben werden \cite{AWSJSSDKD}. Aus diesem Grund werden die Items, wie hier einleitend erwähnt, einzeln entfernt.

%deleteITEM AWS
%https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/DynamoDB.html#deleteItem-property

%QUELLE allg.DYNDB
%https://docs.aws.amazon.com/de_de/AWSCloudFormation/latest/UserGuide/aws-resource-dynamodb-table.html

%QUELLE AUTOSCALING
%https://docs.aws.amazon.com/de_de/amazondynamodb/latest/developerguide/AutoScaling.Console.html
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
Permissions:
        Type: AWS::DynamoDB::Table
        Properties:
            AttributeDefinitions:
                -
                    AttributeName: "Window"
                    AttributeType: "S"
                -
                    AttributeName: "User"
                    AttributeType: "S"
            KeySchema:
                -
                    AttributeName: "Window"
                    KeyType: "HASH"
                -
                    AttributeName: "User"
                    KeyType: "RANGE"
            ProvisionedThroughput:
                ReadCapacityUnits: "1"
                WriteCapacityUnits: "1"
\end{lstlisting}
\bigskip
Unsere Applikation benötigt 3 Tabellen. Eine Tabelle \textit{Files} speichert die Relation zwischen \textit{FileName}, \textit{WindowName} und \textit{User}. So kann man den jeweiligen Desktops die Dateien zuordnen, und auch die Besitzer der Dateien herausfinden. In der zweiten Tabelle \textit{Windows} werden der Desktop Namen \textit{WindowName}, der Besitzer \textit{Owner} und ein Flag ob der Desktop pubic ist oder nicht gespeichert.Die dritte Tabelle \textit{Permissions} ordnet den Desktops die Berechtigungen einzelner Nutzer zu. Die Spalten lautet hier \textit{Window}, \textit{User}. \textit{Permissions}. Die Permissions der einzelnen Nutzer werden als JSON gespeichert und beinhalten Informationen über das Recht Admin zu sein, lesen, schreiben oder löschen zu dürfen, auf den jeweiligen Desktop. \\
In der Applikation wird bei jeder Operation überprüft ob der jeweilige Nutzer die Berechtigung hat dies zu tun.

\section{Serverless-Functions Lambda}
\label{lambda}
Der FaaS Dienst Lambda wird in unserer Applikation genutzt, um unabhängig von unserer EC2 Instanz die Vorschaubilder bzw. Thumbnails für die Bilder, die die Nutzer hochladen zu generieren. Der Vorteil von Lambda ist, dass man sich nicht um die Laufzeitumgebung kümmern muss und das man keine EC2 Instanz ständig laufen lassen muss, damit eine NodeJS Funktion eventbasierend ausgeführt wird. \\ 
Bei der Konfiguration von Lambda in \textit{Cloudformation} müssen mehrere Ressourcen beachtet werden. \\
Unsere Lambda Funktion benötigt eine Rolle, die sowohl \textit{Permissions} wie \textit{Policies} hält. Die Rolle braucht die Erlaubnis Lambda Funktionen aufzurufen, wenn etwas in unseren \textit{UserBucket} hochgeladen wird. Dies wird folgendermaßen konfiguriert:

\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
LambdaPermission:
    Type: "AWS::Lambda::Permission"
    Properties: 
        Action: "lambda:InvokeFunction"
        FunctionName:
            Fn::GetAtt:
            - LambdaThumbnail
            - Arn
        Principal: "s3.amazonaws.com"
\end{lstlisting}

Außerdem wird eine Policy erstellt, um Logs und S3 Objekte zu schreiben und XRAYs verfolgen zu können.\\
Die Lambda Funktion benutzt dann diese Rolle, um alle Dinge zu bewerkstelligen die wir für das erstellen der Thumbnails benötigen. Die Lambda Funktion wird folgendermaßen konfiguriert:
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
LambdaThumbnail:
    Type: "AWS::Lambda::Function"
    Properties: 
        Handler: "index.handler"
        Role: 
            Fn::GetAtt: 
                - "LambdaRole"
                - "Arn"
        Code:
            S3Bucket:
                Ref: CodeBucket
            S3Key: "lambda.zip"
        MemorySize: "1024"
        Runtime: "nodejs8.10"
        Timeout: "10"
        TracingConfig:
            Mode: "Active"
\end{lstlisting}
\bigskip
Wie man sieht gibt man in Zeile 3 den Einstiegspunkt mit, benutzt in den folgenden Zeilen die definierte Rolle und greift auf den gezippten Quellcode im definierten CodeBucket zu. Die restlichen Zeilen geben die Parameter für die Laufzeitumgebung an, wie die Arbeitsspeichergröße, den Funktionsname, die Laufzeit, Timeout und das erlaube XRAY Tracing.\\[0.5cm]
Die Funktion wird durch ein S3 \textit{s3:ObjectCreated:*} Event gestartet. Das Thumbnail Script filtert zuerst die Bilder aus den Anfragen, anhand der Dateiendungen heraus. Diese Bilder werden daraufhin verkleinert und in einen zweiten Bucket mit denselben Namen hochgeladen. Dieser zweite Bucket hat denselben Namen wie der Ursprungsbucket mit dem Präfix \textit{thumbs}. Damit kann man nun einfach aus dem NodeJS System auf das Thumbnail zugreifen. \\
Ist das Thumbnail nicht vorhanden, wird ein generisches Vorschaubild erzeugt. 
\subsection{XRAY}
Wer eine Lambda Funktion über Cloudformation definiert und hochfährt wird unweigerlich über XRAY stolpern. Mit einer Fehlermeldung wie: 
\bigskip
\begin{lstlisting}
The provided execution role does not have permissions to
call PutTraceSegments on XRAY
\end{lstlisting}
\bigskip
wird die Erstellung abgebrochen. Wird eine Lambda Funktion durch ein Service wie Cloudformation getriggert, braucht Lambda keine weiteren Berechtigungen, da Lambda diese in den Stack-Kontext bereits besitzt. Unser Lambda Service wird aber durch ein Event getriggert. Wenn ein User etwas in den Userbucket lädt, wird die Lambda Funktion ausgeführt. Dadurch fehlt der Funktion der Stack Kontext, auch wenn er durch jenen erstellt wurde. \\
Seit Anfang 2018 \cite{AWSDe} ist es möglich durch hinzufügen von
\begin{lstlisting}
Properties:
  TracingConfig:
    Mode: "Active"
\end{lstlisting} 
in dem Service \textit{AWS::Lambda::Function} und mit 
\begin{lstlisting}
Properties:
  PolicyDocument:
  -
    Effect: Allow
    Action:
    - xray:PutTraceSegments
    - xray:PutTelemetryRecords
    Resource: '*'
\end{lstlisting} 
in dem Lambda Funktion genutzte Policy \textit{AWS::IAM::Policy}
%QUELLE XRAY
%https://docs.aws.amazon.com/de_de/xray/latest/devguide/xray-services-lambda.html

\section{Route53}
Um die generierte ElasticBeanstalk Domain auf eine sprechender Domain zu mappen, in unserem Fall \textit{www.virtual-desktop.org}, nutzen wir den Route53 Service. Die Konfiguration setzt eine registrierte Route53 Domain bei AWS voraus:
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
RouteDNS:
    Type: AWS::Route53::RecordSet
    Properties:
        HostedZoneName: !Sub
            - ${DName}.
            - DName: !Ref DomainName
        Name: !Sub
            - www.${DName}.
            - DName: !Ref DomainName
        Type: CNAME
        TTL: 900
        ResourceRecords:
        - !GetAtt EnvironmentElasticBS.EndpointURL
\end{lstlisting}
\bigskip
\noindent Der Domain Name wird per Startparameter von den Cloudformation Start-Script gesetzt. Per \textit{ResourceRecords} wird die ElasticBeanstalk Domain gesetzt.
 
\section{Wie arbeiten die Services zusammen}

Um das zusammenarbeiten der einzelnen Services zu demonstrieren, zeigen wir beispielhaft zwei Szenarien.
\begin{itemize}
\item Ein Nutzer lädt ein Bild hoch.
\item Ein Nutzer löscht ein Desktop.
\end{itemize}


Sobald man einen REST Call absetzt ist der erste AWS Service, den man als Anwender nutzt, der Route53 Service, der für das Routing der Domain \textit{www.virtual-desktop.org} auf die ElasticBeanstalk Domain zuständig ist. Dieser nutzt einen LoadBalancer, um auf eine EC2 Instanz zu kommen die dann die Identität des Nutzers anhand seines Authentifizierungscookie mit Cognito überprüft. \\
Die Anfrage des Nutzers wird nun im Nutzerkontext ausführt, falls der Cookie gesetzt und valide ist. Danach wird überprüft ob für den REST Call die benötigten Parameter korrekt gesetzt sind. \\
Dies Schritte werden bei jedem REST Call durchgeführt. Mit Ausnahme der add-, list- und leaveWindow REST Calls werden nun die Permissions aus der Permissiosn Table der DynamoDB aufgerufen und mit den benötigten Permissions für den Call abgeglichen. Falls der Benutzer berechtigt ist wird dieser in seinen Benutzerkontext ausgeführt. Ab diesem Punkt sind weitere Aktionen REST Call abhängig. \\ \\
Dies wird anhand folgender der Szenarien \textit{addFile} und der parallelarbeitenden \textit{removeWindow} gezeigt:

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{AddFile-Szenario.png} 
\caption{Ablauf eines Fileuploades}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{DeleteWindow-Szenario.png}
\caption{Ablauf des Desktop Löschens.}
\end{figure}


\chapter{Besonderheiten}
Im folgenden beleuchten wir möglichst kurz die unser Meinung nach interessanten Stellen der Umsetzung der Applikation.

\section{Entwicklungsumgebung lokal / Env- Variablen in NodeJS}
%- Refs lösen

Bei Elastic-Beanstalk-Projekten wird bei jedem Deploy die gesamte Umgebung mit allen AWS-Resourcen neu gestartet. Dies beinhaltet unter anderem die EC2-Instanz. Da bei Quellcodeänderungen ein Deploy erneut ausgeführt werden muss und die Instanziierung einer EC2-Instanz zeitaufwendig sein kann ist dies für die Entwicklung der Webanwendung nicht praktikabel. Aus diesem Grund wurden in Elastic-Beanstalk, Referenzen \cite{AWSDc} für die dynamisch angelegten Ressourcen erzeugt. Diese Referenzen können in Umgebungsvariablen der EC2-Instanzen übernommen werden, dies geschieht in der \textit{node-env-keys.config} \cite{AWSDd}.\\[0.5cm]
Um eine schnellere Entwicklung voranzutreiben wird dieser Umstand genutzt, indem statische (nicht durch EBS-Deploy generiert) Amazon Web Services erstellt und in die Umgebungsvariablen des Entwicklersystems hinzugefügt werden.
Hierbei ist zu beachten, dass lediglich die EC2-Instanzen durch den lokalen Rechner ersetzt werden. Anzulegende Umgebungsvariablen sind
\textit{AWS\_ACCESS\_KEY\_ID} und \textit{AWS\_SECRET\_ACCESS\_KEY} mit den AWS-Credentials, \textit{COGNITO\_CLIENT} und \textit{COGNITO\_POOL} mit der App-Client-ID eines Cognito-Clients (mit GenerateSecret=false) und der Pool-ID des dazugehörigen Cognito-Pools, \textit{FILES}, \textit{PERMISSIONS} und \textit{WINDOWS} mit den jeweiligen Tabellennamen aus der DynamoDB und \textit{BUCKET} sowie \textit{THUMB\_BUCKET} mit den Bucket-Namen. Weiterhin ist die Lambda-Funktion wie in \ref{lambda} beschrieben kopiert und auf die lokalen Buckets gemappt.  


%REF QUELLE
%https://docs.aws.amazon.com/de_de/AWSCloudFormation/latest/UserGuide/intrinsic-function-reference-ref.html

%EVI VAR
%https://docs.aws.amazon.com/de_de/elasticbeanstalk/latest/dg/environments-cfg-softwaresettings.html


\section{Promise / Dispatcher}
\label{dispatcher}
%ok

Die Funktion der AWS-sdk arbeiten mit Callbacks, jedoch sind Aufgaben wie z.B. das Löschen von Desktops und deren Inhalt parallelisierbar, und müssen synchronisiert werden. Um dies zu bewerkstelligen, und um komplexe Callbackstrukturen zu vermeiden wurde eine \textit{dispatch}-Funktion für solche Aufgaben konzipiert. 
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
async function dispatch(tasks, map, callback) {
    var data = { tasks: tasks,
                 map: map, 
                 result: {}, 
                 errors: [], 
                 propergate: true 
    };
    while(data.tasks.length != 0 && data.propergate) {
        var promises = [];
        for (var i = 0; i < tasks[0].length; i++) {
            var f = function(resolve, reject) {
                    this.tasks[0][i](this, () => {
                    resolve();
                });
            };
            promises.push(new Promise(f.bind(data)))
        }
        await Promise.all(promises);
        data.tasks.splice(0, 1);
    }
    callback(data);
}
\end{lstlisting}
\bigskip
Es wird hier zum einen der Parameter \textit{tasks}, einem Array aus Arrays aus Funktionen, der Form \textit{(dis, done)}, sowie ein Objekt \textit{map}, welches innerhalb der \textit{tasks} über \textit{dis.map} zugreifbar ist, und einer \textit{callback}-Funktion, welche nach Beendigung aller \textit{tasks} ausgeführt und die Resultate und Fehler zurückliefert, übergeben. Der \textit{callback} ist notwendig, da die Funktion asynchron ist. Die \textit{dispatch}-Funktion sorgt dafür, dass die Funktionen der inneren \textit{task}-Arrays parallel durch die Kapselung in \textit{promisses} ausgeführt werden. Der Array selbst wird sequentiell ausgeführt, dies wird durch \textit{await} sichergestellt. Es ist zu dem möglich, während des \textit{dispatch}-Prozesses weitere \textit{tasks} hinzuzufügen (dies wird z.B. beim Löschen von Desktops verwendet). Ermöglicht wird dies, da jede \textit{(dis, done)}-Funktion auf das \textit{data}-Objekt und somit auf das Doppelarray aus Funktionen zugreifen kann. Dadurch ist es den Funktionen auch möglich, Ergebnisse in \textit{results} zu speichern, Fehler in \textit{errors} anzugeben und die weitere Ausführung paralleler Arbeitsschritte durch das setzen von \textit{propergate} auf false zu verhindern. Das \textit{dis} der \textit{(dis, done)}-Funktion wird hierbei auf \textit{data} gebinded, das \textit{done} ist hier eine \textit{callback}-Funktion, welche das \textit{resolve} von \textit{Promise} ausführt. Die Funktion \textit{dispatch} kann wie am folgendem Beispiel der \textit{deleteWindow}-Funktion gezeigt verwendet werden:
\bigskip
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java]

function deleteWindow(username, windowName, callback) {
    var map = { 
        "username": username, 
        "windowName": windowName
    };
    dispatch([[checkParams], 
              [getPermissions], 
              [checkPermissions("owner")], 
              [deleteWindowDynamoDB, 
               removeFilesAndFileInfos, 
               deleteWindowPermissonsDynamoDB
             ]], map, (data) => {
        callback(reply(data));
    });
}
\end{lstlisting}
\bigskip
\noindent Zunächst wird der \textit{username} und \textit{windowName} durch \textit{checkParams} auf Existenz geprüft. Anschließend werden die Berechtigungen für den Benutzer durch \textit{getPermissions} aus der DynamoDB für den angegeben Desktop abgefragt. Die Berechtigungen sind nun im Kontext von \textit{checkPermissions} über \textit{dis.data} zugreifbar. Die \textit{checkPermissions}-Funktion setzt \textit{propagate} auf \textit{false}, falls der Nutzer nicht Besitzer des Desktops ist (und einen Fehler in \textit{dis.errors}-Array schreiben). Ansonsten wird der Desktop und alle dazugehörigen Inhalte und Berechtigungen gelöscht.    

\section{Model-View-Controller}
%ok
Um die parallele Entwicklung des Projektes gewährleisten zu können wird ein Model-View-Controller verwendet. Das Model beinhaltet hierbei die Amazon Web Services S3, DynamoDB, Cognito welche durch die \textit{virtual-desktop.js} in Schnittstellen abstrahiert wird und mittels NodeJS-Express-Server für den Controller zugänglich ist. Diese Abstraktion wurde vorgenommen, damit der NodeJS-Express-Server durch AWS-Lambda substituiert werden kann. Der NodeJS-Express-Server wird durch den Elastic-Beanstalk bereitgestellt. AWS-Lambda wird im Backend verwendet um für neue Dateien, welche durch den Nutzer in den S3-Bucket gespeichert werden Thumbnails zu erstellen.\\
Die Schnittstelle \textit{api.js} im Frontend wird durch den Controller erweitert. Dieser Controller reagiert auf die Eingaben des Nutzers im Frontend, indem Controller-Funktionen angesprochen werden. Bei Bedarf werden Backend-Funktionen durch den Controller angesprochen und/oder im Frontend Events ausgelöst, wodurch dieses aktualisiert werden kann.
Die Verwendung eines Controllers ist vorteilhaft um die spätere Einbindung von Push-Notifications mit geringem Aufwand zu realisieren.

\section{Streaming Download / Upload}
\label{updown}
%vielleicht screenshot von netzwerk tab bei video stream - stückchen

Um Dateien von und in den S3-Bucket zu laden, können Buffer verwendet werden, dies bedeutet das die Dateien zunächst im Arbeitsspeicher oder im Speicher des NodeJS-Express-Server zwischengespeichert werden müssen. Da eine EC2-Instanz nur über ein begrenztes Volumen an Speicher verfügt, ist das Buffern von Dateien nicht empfehlenswert (erhöhte Kosten, Skalierung von EC2-Instanzen) \cite{AWS}.\\
%https://aws.amazon.com/de/ec2/pricing/on-demand/
Aus diesem Grund werden die Dateien in diesem Projekt vom Backend gestreamt. Hierzu wurden die folgenden Express-Middleware-Bibliotheken geprüft:

\begin{itemize}
\item multer
\item express-fileupload
\item express-busboy
\item busboy-body-parser
\item busboy
\end{itemize}

%TO DO: QUELLEN EINTRAGEN - in .BIB
\noindent Die Middleware \textit{multer} und \textit{express-fileupload} kommen für das gestreamte Hochladen von Dateien auf den S3-Bucket nicht in Frage, da sie keine Streams unterstützen sondern entweder auf der Festplatte speichern  oder im Arbeitsspeicher buffern [quelle: multer, fileupload].
%multer: https://www.npmjs.com/package/multer
%fileupload: https://www.npmjs.com/package/express-fileupload
Um \textit{busboy} im Kontext von NodeJS-Express verwenden zu können, kann \textit{express-busboy} verwendet werden. Allerdings ist diese Bibliothek ebenfalls nur im Stande auf die Festplatte zu speichern. Auch der \textit{busboy-body-parser} stellte sich bei näherer Betrachtung des Quellcode als ungeeignet heraus, da auch dieser nur im Arbeitsspeicher buffert \cite{LeonardMartin}.\\
%https://github.com/lennym/busboy-body-parser/blob/master/index.js
Die Bibliothek \textit{busboy} hingegen liest den HTTP-Request als Stream ein und bietet auch die Dateien als Stream an \cite{busboy}.
%https://www.npmjs.com/package/busboy
Die Problematik, die sich hieraus ergibt, ist das für das Speichern der Datei der Desktop auf dem die Datei gespeichert werden soll bekannt sein muss. Da \textit{busboy} allerdings auf dem HTTP-Request-Stream arbeitet muss der Desktopname vor der Datei im \textit{multipart/form-data} stehen. Um \textit{busboy} zu verwenden wurde daher eine minimalistische Middleware \textit{busboySync.js} entwickelt \cite{Express}.
%https://expressjs.com/en/guide/using-middleware.html
Diese Middleware kommt in allen Resourcen als Router-Middleware des NodeJS-Express-Servers zum Einsatz, welche \textit{multipart/form-data} verarbeitet. Ausnahme hierbei bildet die \textit{/addFile}-Resource, welche aus oben genannten Gründen \textit{busboy} nativ verwendet.\\
Für den Download von Dateien wird die \textit{/getStream}-Resource verwendet, diese liefert für typische Range-Requests der Form
\begin{lstlisting}
bytes=x-y
\end{lstlisting}
, wobei x das Start-byte und y das End-byte darstellt (y kann auch entfallen), ein HTTP-Response-206 (Partial Content) zurück \cite{HTP}.

%QUELLE: Range,206 723
%https://www.rfc-editor.org/rfc/rfc7233.txt 

\section{Nginx Configuration}

In AWS hat der Nginx in jeder EC2 Instanz eine Standardkonfiguration. Diese Standard Configuration setzt zum Beispiel mit \lstinline|/client_max_body_size 1m;| \cite{NGINX} die maximale Dateigröße zur Kommunikation auf 1MB.\\
Lädt man nun Dateien in den ElasticBeanstalk bzw. auf die EC2 Instanz hoch oder hinunter, wird ein \glqq413 (Request Entity Too Large)\grqq geworfen. Auf dieses Problem stößt jeder, der mit einer EC2 Instanz arbeitet und mit größeren Dateien in der EC2 Instanz arbeiten möchte.
Mit einer \lstinline|/nginx.config| in einen \lstinline|/.ebextensions| kann man die Nginx Configuration anpassen. 
Unsere Configuration passt lediglich die \lstinline|/client_max_body_size| an:\\
\begin{lstlisting}[xleftmargin=\parindent,numbers=left,numberstyle=\small,numbersep=8pt,frame=L,mathescape=true, basicstyle=\small, language=Java, lineskip={1.0pt}]
files:
  /etc/nginx/conf.d/proxy.conf:
    mode: "000644"
    owner: root
    group: root
    content: |
      client_max_body_size 0;
\end{lstlisting}
\bigskip
\noindent Wir schreiben mit dieser Config das file in \lstinline|/etc/nginx/conf.d/proxy.conf| und setzen direkt die richtigen Rechte. Der Content wird ebenfalls in der Configuration gesetzt und beinhaltet lediglich unsere \lstinline|"client_max_body_size"|  Regel. Diese wird für uns auf 0 gesetzt und bewirkt, dass beliebig große Dateien in der EC2 Instanz behandelt werden können.


%QUELLE NGINX
%https://nginx.org/en/docs/http/ngx_http_core_module.html#client_max_body_size

\chapter{Analyse}
\section{Kosten}
%umrechnen Requests auf den Nutzer. Maximalen Storage pro Nutzer enführen
Um die etwaigen Kosten abzuschätzen haben wie den \textit{AWS-Gesamtbetriebskostenrechner} bedient. [QUELLE: KOSTENRECHNER] 
%QUELLE KOSTENRECHNER
%https://calculator.s3.amazonaws.com
\noindent Zur Kalkulation der Betriebskosten betrachten wir die laufenden Monatskosten für die folgenden Szenarien:\\
\begin{itemize}
\item Die Anwendung wird von 10 Nutzern genutzt.
\item Die Anwendung wird von 1000 Nutzern genutzt.
\item Die Anwendung wird von 1000000 Nutzern genutzt.
\end{itemize}
Um die Kosten einer Anwendung in AWS schätzen zu können, ist eine detaillierte Analyse der einzelnen Funktionen der Anwendung nötig. Wir haben sowohl den Datendurchsatz, wie auch die benötigten Requests der einzelnen API Aufrufe betrachtet. Auch der benötigte Traffic der eigentlichen Anwendungsauslieferung und Lamba muss betrachtet werden.\\ 
Ein Nutzer bedient in unseren Szenarien folgende Funktionen jeden Tag. Diese Daten werden danach auf ein Monat hochgerechnet. \\
\textbf{Einen Nutzer pro Tag} ...
\begin{enumerate}
\item kann maximal 5GB in seinen Desktop speichern.
\item logt sich 3 mal an Tag ein.
\item lädt Dateien hoch wie:
\begin{enumerate}
\item 3 Bilder (wie jpeg, jpg, png...) 9MB
\item 2 Textdateien (txt, docx, odt...) 2MB
\item 3 Musik (mp3) 12MB
\item 0,3 Videos (avi, mp4) 500MB
\end{enumerate}
\item erstellt oder löscht 1/6 Desktop
\item switcht 6 Desktops
\item setzt und löscht 1/2 Permissions
\item setzt 1/18 Desktop public
\end{enumerate}
Damit haben wir folgende Aufrufe oder Traffic für \textbf{einen Nutzer pro Tag}
\begin{enumerate}
\item DynamoDB GET: 264.2
\item DynamoDB SCAN: 38.33
\item DynamoDB DELETE: 8.96
\item DynamoDB PUT: 8.96
\item S3 GET: 83
\item S3 PUT: 8,3
\item S3 DELETE: 8,3
\item Lambda: 16,6
\item Cognito: 1 MAU
\item S3 DATA: 173 MB
\item Traffic Service-AWS: 1 MB
\item Traffic VirtualDesktop: 173 MB
\item Route 53 Abfragen: 110
\end{enumerate}
Diese Daten wurden für die weitere Berechnung pro Monat herangezogen.
Für die Berechnung wurde der AWS Simply Monthly Calculator Rechner bedient. [QUELLE: AWSRECHNER] Für Lambda wurde folgender Rechner genutzt. [QUELLE: LAMBDARECHNER]
\\

\begin{figure}[H]
\begin{tabular}{|l|l|l|l|l}
\cline{1-4}
      \textbf{Kosten pro Monat}    & \textbf{10 Nutzer} & \textbf{1000 Nutzer} & \textbf{1000000 Nutzer} &  \\ \cline{1-4}
\textbf{EC2} & 4,18 USD & 8,86 USD & 5.203,66 USD &  \\ 
\cline{1-4}
\textbf{S3} & 0,14 USD & 11,06 USD &     9.936,76 USD &  \\ 
\cline{1-4}
\textbf{Route53} & 0,90 USD & 2,10 USD & 882,50 USD &  \\ 
\cline{1-4}
\textbf{DynamoDB} & 0,31 USD & 3,05 USD & 13.349,48 USD &  \\ 
\cline{1-4}
\textbf{AWS Data IN} & 0,00 USD & 0,00 USD & 0,00 USD      &  \\ 
\cline{1-4}
\textbf{AWS Data OUT} & 9,63 USD & 969,11 USD & 543.891,11 USD &  \\
\cline{1-4}
\textbf{Cognito} & 0,50 USD & 50,00 USD & 4.415,00 USD &  \\ \cline{1-4}
\textbf{LAMBDA} & 0,04 USD & 4,39 USD & 4.392,00 USD &  \\ \cline{1-4}
\textbf{Gesamt} & \textbf{15,70 USD} & \textbf{1048,57 USD} & \textbf{582.070,51 USD} &  \\ \cline{1-4}
\textbf{Kosten pro Nutzer} & 1,57 USD & 1,05 USD & 0,58 USD &  \\ \cline{1-4}
\end{tabular}
\end{figure}

Dies ergibt folgende Kalkulation in Euro:
\begin{enumerate}
	\item 10 Nutzer pro Monat: 15,20 US-Dollar oder \textbf{13,30} Euro (Stand 23.01.2019)
	\item 1000 Nutzer pro Monat: 1048,57 US-Dollar oder \textbf{923,75} Euro (Stand 23.01.2019)
	\item 1000000 Nutzer pro Monat: 582.070,51 US-Dollar oder \textbf{509.311,70 Euro} (Stand 23.01.2019) 
\end{enumerate}

Es entsteht folgender Traffic aus der AWS zu den Nutzer:
\begin{enumerate}
	\item 10 Nutzer pro Monat: 53940 MB = 53,94 GB
	\item 1000 Nutzer pro Monat: 5394000 MB = 5394 GB = 5,394 TB
	\item 1000000 Nutzer pro Monat: 5394000000 MB = 5394000 GB = 5394 TB = 5,394 PB
\end{enumerate}
\begin{figure}[H]
\centering
\includegraphics[scale=0.8]{costs-overview.png}
\caption{Kosten der Service im Vergleich}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[scale=0.75]{million-costs.png}
\caption{Kosten der Services für 1 Millionen Nutzer}
\end{figure}

\subsection{Bewertung Kosten}
Interessant an der Kostenrechnung ist sowohl die Entwicklung der einzelnen Services im Vergleich, wie auch die Entwicklung der Kosten pro Nutzer. So Erkennt man, dass in allen Fällen die AWS Data OUT, also die Kosten die AWS veranschlagt um Daten aus der AWS hinaus zu transportieren in allen Szenarien mit Abstand die höchsten sind. \\
Weitaus interessanter ist die Entwicklung der Kosten pro Nutzer. Auch wenn der Kostenbetrag am Ende sehr hoch klingt, wäre er bereits ab einen Preis pro Nutzer von 0,60 USD gedeckt. Unser Dienst wäre dementsprechend schnell rentabel.


%10 = https://calculator.s3.amazonaws.com/index.html?lng=de_DE#key=calc-8CABA020-322B-4A90-9C2A-32D0DAA9BF27&r=FRA
%1000 = https://calculator.s3.amazonaws.com/index.html?lng=de_DE#key=calc-3DA5EE1E-4F75-498F-8036-433A14F2C7C5&r=FRA
%1000000 = https://calculator.s3.amazonaws.com/index.html?lng=de_DE#key=calc-522435CB-583B-4AEE-9FDD-E90FFB3BED47&r=FRA


%QUELLE LAMBDARECHNER
%https://dashbird.io/lambda-cost-calculator/
%QUELLE AWSRECHNER
%https://calculator.s3.amazonaws.com
\section{Skalierung}
Die Services Route53, Cognito, DynamoDB, S3 und Lambda skalieren grundsätzlich beliebig, lediglich die Wirtschaftlichkeit des verwendeten Service Elastic Beanstalk ist von der Implementierung der Geschäftslogik abhängig. Um die Geschäftslogik wirtschaftlich zu halten müssen möglichst viele Nutzer von einer einzelnen EC2-Instanz die von EBS instanziiert wird verarbeitet werden. Um eine größere Nutzerzahl zu gewährleisten wurde der Up- und Download-Streaming wie in \ref{updown} beschrieben implementiert, denn ohne Streaming würde der Arbeitsspeicher für gecachte Dateien dafür sorgen weitere EC2-Instanzen durch EBS auszuführen.
Um weiterhin genutzte Ports auf dem Webserver zu reduzieren wurde zu dem der Dispatcher wie in \ref{dispatcher} beschrieben entwickelt. Dieser sorgt dafür, dass parallelisierbare Aufgaben parallel ausgeführt werden können. Dadurch ist die Belegungszeit für den Port geringer.\\
Wie bereits erwähnt ist die DynamoDB im Gegensatz zu einer SQL-Datenbank beliebig skalierbar. Dieser Vorteil wird für die \textit{Permissions}-Tabellen genutzt wie in \ref{db} beschrieben.

   

\chapter{Ausblick}
Im Zuge einer Weiterentwicklung haben wir folgende Punkte gefunden, wodurch man den Funktionsumfang oder die Kosten bei AWS reduzieren könnte. Durch unser ständiges Augenmerk bei der Entwicklung auf Erweiterbarkeit, sollte es recht einfach sein unseren Code zu erweitern. \\
Folgende Punkte bieten Ausbaupotential:
\begin{itemize}
\item Wir haben eine eigene EC2 Instanz auf einen ElasticBeanstalk anstatt Lambda Funktionen gewählt, auch weil wir vor hatten Sockets zu implementieren. Diese Sockets würden den Nutzer die Möglichkeit geben Änderungen auf einen geteilten Desktop live zu sehen. 
\item Dank unserer vorausschauenden Programmierstruktur, haben wir die Funktionen die aufgerufen werden können wie, Auflisten der Elemente im Desktop, Auflisten der verschiedenen Desktops usw. möglichst weit gekapselt. Dadurch wäre der komplette Umbau auf Lambda theoretisch möglich. Dennoch würden wir keinen kompletten Umstieg auf Lambda empfehlen, da es auch Gründe gibt die bei manchen Funktionen dagegen spricht. Wie zum Beispiel das feste Lambda-Limit der Zeitüberschreitung von 15 Minuten. Ein Up- oder Download bei großen Dateien kann aber auch über 15 Minuten dauern und würde dann zum Abbruch führen.
\item Ein relativ einfaches Feature, dass man hinzufügen könnte wäre das hinzufügen eines SSL Zertifikates zu der EC2 Instanz beziehungsweise zum Route53 Service, um das Surfen über verschlüsselte Aufrufe über https zu ermöglichen.
\item Zurzeit löscht der Lambda Service die gerenderten Bilder nicht wieder aus den ThumBucket heraus. Dies als Funktion hinzuzufügen, würde ebenfalls geringere S3 Kosten bedeuten.
\item Gerade bei der Kostenoptimierung wäre ein direkter Zugriff auf die S3 Daten von Vorteil. Wie man in unserer Übersicht der Betriebskosten sieht ist dieses \emph{durchschleusen} ein großer Kostenfaktor. AWS bietet an mit speziellen \glqq Whitelist\grqq  Cookies Nutzer direkt auf die S3 Daten zugreifen zu lassen, auch bei Streams.
\item Ein weitere Idee die Kosten zu verringern, wäre die Nutzerdaten auf keinen S3-Bucket zu lagern sondern auf den AWS-Glacier. Dieser verspricht geringere Kosten bei vielen Datenmengen.
\item Auch das verlagern des Thumbnailservices in die ständig laufenden EC2 Instanzen würden die Kosten für den Lambda Service einsparen.
\item Das Setup Script nimmt zur Zeit Parameter entgegen, diese können auf einem unix system mit zum Beispiel dem Kommandozelenprogramm "top" von anderen Nutzern eingesehen werden. Da die Parameter die AWS Credials beinhalten, sollte das Script so angepasst werden, dass diese aus der Credials Datei von AWS ausgelesen werden (wie auch die aws-cli) beziehungsweiße die Credials innerhalb der Anwendung vom Benutzer abgefragt werden.
\end{itemize}


\clearpage
\bibliographystyle{alpha}
\bibliography{documentation}
%\bibliographystyle{apalike}

\end{document}